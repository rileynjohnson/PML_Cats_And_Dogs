{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Machine Learning\n",
    "### Assignment 7 - Image Processing with Convolutional Neural Networks(CNN)\n",
    "\n",
    "Description:\n",
    "This assignment follows the same structure as Assignment 6. We will employ at least a 2x2 completely crossed experimental design. We will again use a simple training-and-test regimen, perhaps with a three-way partitioning of the data into training, dev, and test sets. The factors in the design may include numbers of layers and/or nodes within layers, types of layers (convolutional or pooling), and/or other hyperparameters. We will utilize convolutional neural networks (CNNs) within Python TensorFlow. \n",
    "\n",
    "The case data present a binary classification task, a subset of the data from a Kaggle competition in 2013\n",
    "https://www.kaggle.com/c/dogs-vs-cats\n",
    "\n",
    "The original data consisted of 25,000 images of cats and dogs. To ensure that the problem may be run on typical personal computers with limited memory and no graphical processing units (GPUs), we work with only 2,000 images: 1,000 cat images and 1,000 dog images. The original image files are provided in a zip archive:\n",
    "\n",
    "cats_dogs_images.zip\n",
    "\n",
    "After the data have been prepared for analysis in a jump-start program \n",
    "(included in the zip archive cats-dogs-jump-start-v002.zip under Modules / Technology Resources), \n",
    "we will divide the images into training, dev, and test sets for evaluating alternative neural network models per our experimental design.\n",
    "\n",
    "Management Problem\n",
    "Assume that we are providing advice to a website provider who is looking for tools to automatically label images provided by end users. As we look across the factors in the study, making recommendations to management about image classification, we are most concerned about achieving the highest possible accuracy in image classification. That is, we should be willing to sacrifice training time for model accuracy. What type of machine learning model works best? If it is a convolutional neural network, what type of network should we use? Part of this recommendation may concern information about the initial images themselves (input data for the classification task). What types of images work best?\n",
    "\n",
    "Programming Resources\n",
    "Refer once again to the programming resources cited under Assignment 6. Convolutional neural network coding examples are provided in the Géron (2017) textbook.\n",
    "\n",
    "Géron, A. (2017). Hands-on machine learning with Scikit-Learn & TensorFlow: Concepts, tools, and techniques to build intelligent systems. Sebastopol, CA: O'Reilly. [ISBN-13 978-1-491-96229-9]. Chapter 13: Convolutional Neural Networks (pp. 353–378)  Source code available here (Links to an external site.)Links to an external site.. \n",
    "\n",
    "Regarding memory issues. With the large number of parameters being fit in deep learning tasks, out-of-memory errors may be encountered on personal computers. Géron (2017, p. 363) provides these suggestions with regard to CNNs:\n",
    "\n",
    "If training crashes because of an out-of-memory error, you can try reducing the mini-batch size. Alternatively, you can try reducing dimensionality using a stride, or removing a few layers. Or you can try using 16-bit floats instead of 32-bit floats.\n",
    "\n",
    "Additional background regarding computer vision, CNNs, and TensorFlow is provided under:\n",
    "\n",
    "Modules / Technology Resources / Convolutional Neural Networks with TensorFlow\n",
    "\n",
    " \n",
    "\n",
    "Grading Guidelines (50 points)\n",
    "(1) Data preparation, exploration, visualization (10 points)\n",
    "(2) Review research design and modeling methods (10 points)\n",
    "(3) Review results, evaluate models (10 points)\n",
    "(4) Implementation and programming (10 points)\n",
    "(5) Exposition, problem description, and management recommendations (10 points)\n",
    "\n",
    " \n",
    "Deliverables and File Formats\n",
    "- Please upload the completed jupyter notebook (PREFERRED)\n",
    "\n",
    "OR\n",
    "\n",
    "Create a folder or directory with all supplementary files with your last name at the beginning of the folder name, compress that folder with zip compression, and post the zip-archived folder under the assignment link in Canvas. The following files should be included in an archive folder/directory that is uploaded as a single zip-compressed file. (Use zip, not StuffIt or any 7z or other compression method.)\n",
    "\n",
    "1. Provide a double-spaced paper with a two-page maximum for the text. The paper should include (1) a summary and problem definition for management; (2) discussion of the research design, measurement and statistical methods, traditional and machine learning methods employed; (3) overview of programming work; and (4) review of results with recommendations for management. (The paper must be provided as an Adobe Acrobat pdf file. MS Word files are NOT acceptable.)\n",
    "\n",
    "2. Files or links to files should be provided in the format as used by the Python program.\n",
    "\n",
    "3. Complete program code in Python used to access and analyze the data. The code should be submitted as a plain text file, so it can be executed as a program in a single Python program execution within an interactive Python shell. (You may include a Python notebook in addition to the complete program code.) If there are calls to Python modules, ensure that the directory structure is maintained so that the main program may be fully executed. \n",
    "\n",
    "4. Output from the program, such as console listing/logs, text files, and graphics output for visualizations. If you use Professional Studies database servers or systems, include Linux logs of your sessions as plain text files.\n",
    "\n",
    "5. List file names and descriptions of files in the zip-compressed folder/directory.\n",
    "\n",
    "\n",
    "Formatting Python Code\n",
    "Refer to Google’s Python Style Guide (Links to an external site.)Links to an external site. for ideas about formatting Python code\n",
    "\n",
    "Also refer to Google’s TensorFlow Style Guide (Links to an external site.)Links to an external site.\n",
    "\n",
    "Comment often and in detail, highlighting major sections of code, describing the thinking behind the modeling and programming methods being employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#ignore tensorflow related warnings\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# Initial deep neural network set-up from \n",
    "# Géron, A. 2017. Hands-On Machine Learning with Scikit-Learn \n",
    "#    & TensorFlow: Concepts, Tools, and Techniques to Build \n",
    "#    Intelligent Systems. Sebastopol, Calif.: O'Reilly. \n",
    "#    [ISBN-13 978-1-491-96229-9] \n",
    "#    Source code available at https://github.com/ageron/handson-ml\n",
    "#    See file 10_introduction_to_artificial_neural_networks.ipynb \n",
    "#    Revised from MNIST to Cats and Dogs to begin Assignment 7\n",
    "#    #CatsDogs# comment lines show additions/revisions for Cats and Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports for our work\n",
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd  # data frame operations  \n",
    "import numpy as np  # arrays and math functions\n",
    "import matplotlib.pyplot as plt  # static plotting\n",
    "import re # regular expressions\n",
    "import scipy\n",
    "import os # Operation System\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import cv2\n",
    "#import seaborn as sns\n",
    "start_time_overall = time.clock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Secure dataset and image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory\n",
      "/home/rj/PML/Week 7 Cats and Dogs\n"
     ]
    }
   ],
   "source": [
    "# create a data directory in the present working directory\n",
    "os.getcwd() \n",
    "os.chdir('.')\n",
    "print('Working Directory')\n",
    "print(os.getcwd())  \n",
    "random_seed=9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path variables ( make sure the directories & the images exist )\n",
    "cat_image_dir_name = './cats_dogs_images/cats'\n",
    "dog_image_dir_name = './cats_dogs_images/dogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Functions\n",
    "# Sorting of file names facilitated by\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "def sort_nicely(l):\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "    \n",
    "# Generate list of file names, excluding hidden files    \n",
    "def directory_list (dir_name):\n",
    "    start_list = os.listdir(dir_name)\n",
    "    end_list = []\n",
    "    for file in start_list:\n",
    "        if (not file.startswith('.')):\n",
    "            end_list.append(file) \n",
    "    end_list.sort(key = alphanum_key)        \n",
    "    return(end_list)        \n",
    "\n",
    "cat_file_names = directory_list(cat_image_dir_name)\n",
    "cat_file_names = cat_file_names[0:1000]\n",
    "dog_file_names = directory_list(dog_image_dir_name) \n",
    "dog_file_names = dog_file_names[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Convert image to numpy array. 3 channels for color  and 1 converted to grayscale\n",
    "#   Info on npy binary format for saving numpy arrays https://towardsdatascience.com/\n",
    "def parse_grayscale(image_file_path):\n",
    "    image = cv2.imread(image_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return(image)\n",
    "    \n",
    "def parse_color(image_file_path):\n",
    "    image = cv2.imread(image_file_path, cv2.IMREAD_COLOR)\n",
    "    # Default cv2 is BGR... need RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return(image)\n",
    "  \n",
    "def parse_grayscale_and_resize(image_file_path, size = (64, 64)):\n",
    "    image = cv2.imread(image_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, size)\n",
    "    return(image)\n",
    "\n",
    "def parse_color_and_resize(image_file_path, size = (64, 64)):\n",
    "    image = cv2.imread(image_file_path, cv2.IMREAD_COLOR)\n",
    "    # Default cv2 is BGR... need RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, size)\n",
    "    return(image)  \n",
    "    \n",
    "def show_grayscale_image(image):\n",
    "    plt.imshow(image, cmap = 'gray') \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_color_image(image):\n",
    "    plt.imshow(image) \n",
    "    plt.axis('off')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cat image file shapes:\n",
      "\n",
      "\n",
      "\n",
      "Dog image file shapes:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Examine dimensions of original raster images \n",
    "cats_shapes = []\n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_color(image_file_path)\n",
    "    cats_shapes.append(image.shape)\n",
    "print('\\n\\nCat image file shapes:\\n')    \n",
    "#print(cats_shapes)    \n",
    "\n",
    "dogs_shapes = []\n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_color(image_file_path)\n",
    "    dogs_shapes.append(image.shape)    \n",
    "print('\\n\\nDog image file shapes:\\n') \n",
    "#print(dogs_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save numpy array objects for analysis \n",
    "from pathlib import Path\n",
    "my_file = Path('./cats_dogs_arrays_1000')\n",
    "if my_file.exists():\n",
    "    import shutil\n",
    "    shutil.rmtree(my_file)\n",
    "\n",
    "outdir = './cats_dogs_arrays_1000'\n",
    "os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image files to 64x64 color or grayscale arrays\n",
      "\n",
      "Run complete\n"
     ]
    }
   ],
   "source": [
    "# Create Numpy Image Arrays\n",
    "#----------------------------------------------------------------------\n",
    "print('\\nProcessing image files to 64x64 color or grayscale arrays')\n",
    "# Create cats_1000_64_64_3 and numpy array for 1000 cat images in color\n",
    "start_time_m1=time.clock()\n",
    "cats_1000_64_64_3 = np.zeros((1000, 64, 64, 3))  \n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_color_and_resize(image_file_path, size = (64, 64))\n",
    "    cats_1000_64_64_3[ifile,:,:,:] = image\n",
    "       \n",
    "# Create dogs_1000_64_64_3 and numpy array for 1000 dog images in color   \n",
    "dogs_1000_64_64_3 = np.zeros((1000, 64, 64, 3))  \n",
    "for ifile in range(len(dog_file_names)):\n",
    "    image_file_path = os.path.join(dog_image_dir_name, dog_file_names[ifile])\n",
    "    image = parse_color_and_resize(image_file_path, size = (64, 64))\n",
    "    dogs_1000_64_64_3[ifile,:,:,:] = image\n",
    "\n",
    "# Create cats_1000_64_64_1 and numpy array for 1000 cat images in grayscale\n",
    "cats_1000_64_64_1 = np.zeros((1000, 64, 64, 1))  \n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_grayscale_and_resize(image_file_path, size = (64, 64))\n",
    "    cats_1000_64_64_1[ifile,:,:,0] = image\n",
    "       \n",
    "# Create dogs_1000_64_64_1 and numpy array for 1000 dog images in grayscale   \n",
    "dogs_1000_64_64_1 = np.zeros((1000, 64, 64, 1))  \n",
    "for ifile in range(len(dog_file_names)):\n",
    "    image_file_path = os.path.join(dog_image_dir_name, dog_file_names[ifile])\n",
    "    image = parse_grayscale_and_resize(image_file_path, size = (64, 64))\n",
    "    dogs_1000_64_64_1[ifile,:,:,0] = image\n",
    "    \n",
    "# Save numpy array objects for analysis       \n",
    "disk_time_m1=time.clock()\n",
    "np.save(os.path.join(outdir, 'cats_1000_64_64_3.npy'), cats_1000_64_64_3)\n",
    "np.save(os.path.join(outdir, 'dogs_1000_64_64_3.npy'), dogs_1000_64_64_3)\n",
    "np.save(os.path.join(outdir, 'cats_1000_64_64_1.npy'), cats_1000_64_64_1)\n",
    "np.save(os.path.join(outdir, 'dogs_1000_64_64_1.npy'), dogs_1000_64_64_1)\n",
    "disk_time = time.clock() - disk_time_m1\n",
    "print('\\nRun complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image files to 128x128 color or grayscale arrays\n",
      "\n",
      "Run complete\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "print('\\nProcessing image files to 128x128 color or grayscale arrays')\n",
    "\n",
    "# Create cats_1000_128_128_3 and numpy array for 1000 cat images in color\n",
    "cats_1000_128_128_3 = np.zeros((1000, 128, 128, 3))  \n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_color_and_resize(image_file_path, size = (128, 128))\n",
    "    cats_1000_128_128_3[ifile,:,:,:] = image\n",
    "       \n",
    "# Create dogs_1000_128_128_3 and numpy array for 1000 dog images in color   \n",
    "dogs_1000_128_128_3 = np.zeros((1000, 128, 128, 3))  \n",
    "for ifile in range(len(dog_file_names)):\n",
    "    image_file_path = os.path.join(dog_image_dir_name, dog_file_names[ifile])\n",
    "    image = parse_color_and_resize(image_file_path, size = (128, 128))\n",
    "    dogs_1000_128_128_3[ifile,:,:,:] = image\n",
    "\n",
    "# Create cats_1000_128_128_1 and numpy array for 1000 cat images in grayscale\n",
    "cats_1000_128_128_1 = np.zeros((1000, 128, 128, 1))  \n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_grayscale_and_resize(image_file_path, size = (128, 128))\n",
    "    cats_1000_128_128_1[ifile,:,:,0] = image\n",
    "       \n",
    "# Create dogs_1000_128_128_1 and numpy array for 1000 dog images in grayscale   \n",
    "dogs_1000_128_128_1 = np.zeros((1000, 128, 128, 1))  \n",
    "for ifile in range(len(dog_file_names)):\n",
    "    image_file_path = os.path.join(dog_image_dir_name, dog_file_names[ifile])\n",
    "    image = parse_grayscale_and_resize(image_file_path, size = (128, 128))\n",
    "    dogs_1000_128_128_1[ifile,:,:,0] = image   \n",
    "\n",
    "    \n",
    "# Save numpy array objects for analysis \n",
    "disk_time_m1=time.clock()\n",
    "np.save(os.path.join(outdir, 'cats_1000_128_128_3.npy'), cats_1000_128_128_3)\n",
    "np.save(os.path.join(outdir, 'dogs_1000_128_128_3.npy'), dogs_1000_128_128_3)\n",
    "np.save(os.path.join(outdir, 'cats_1000_128_128_1.npy'), cats_1000_128_128_1)\n",
    "np.save(os.path.join(outdir, 'dogs_1000_128_128_1.npy'), dogs_1000_128_128_1)\n",
    "disk_time = disk_time + time.clock() - disk_time_m1\n",
    "print('\\nRun complete')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image files to 256x256 color or grayscale arrays\n",
      "\n",
      "Run complete\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "print('\\nProcessing image files to 256x256 color or grayscale arrays')\n",
    "# Create cats_1000_256_256_3 and numpy array for 1000 cat images in color\n",
    "cats_1000_256_256_3 = np.zeros((1000, 256, 256, 3))  \n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_color_and_resize(image_file_path, size = (256, 256))\n",
    "    cats_1000_256_256_3[ifile,:,:,:] = image\n",
    "       \n",
    "# Create dogs_1000_256_256_3 and numpy array for 1000 dog images in color   \n",
    "dogs_1000_256_256_3 = np.zeros((1000, 256, 256, 3))  \n",
    "for ifile in range(len(dog_file_names)):\n",
    "    image_file_path = os.path.join(dog_image_dir_name, dog_file_names[ifile])\n",
    "    image = parse_color_and_resize(image_file_path, size = (256, 256))\n",
    "    dogs_1000_256_256_3[ifile,:,:,:] = image\n",
    "\n",
    "# Create cats_1000_256_256_1 and numpy array for 1000 cat images in grayscale\n",
    "cats_1000_256_256_1 = np.zeros((1000, 256, 256, 1))  \n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_grayscale_and_resize(image_file_path, size = (256, 256))\n",
    "    cats_1000_256_256_1[ifile,:,:,0] = image\n",
    "       \n",
    "# Create dogs_1000_256_256_1 and numpy array for 1000 dog images in grayscale   \n",
    "dogs_1000_256_256_1 = np.zeros((1000, 256, 256, 1))  \n",
    "for ifile in range(len(dog_file_names)):\n",
    "    image_file_path = os.path.join(dog_image_dir_name, dog_file_names[ifile])\n",
    "    image = parse_grayscale_and_resize(image_file_path, size = (256, 256))\n",
    "    dogs_1000_256_256_1[ifile,:,:,0] = image\n",
    "    \n",
    "# Save numpy array objects for analysis \n",
    "disk_time_m1=time.clock()\n",
    "np.save(os.path.join(outdir, 'cats_1000_256_256_3.npy'), cats_1000_256_256_3)\n",
    "np.save(os.path.join(outdir, 'dogs_1000_256_256_3.npy'), dogs_1000_256_256_3)\n",
    "np.save(os.path.join(outdir, 'cats_1000_256_256_1.npy'), cats_1000_256_256_1)\n",
    "np.save(os.path.join(outdir, 'dogs_1000_256_256_1.npy'), dogs_1000_256_256_1)\n",
    "disk_time = disk_time + time.clock() - disk_time_m1\n",
    "print('\\nRun complete')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image files to 512x512 color or grayscale arrays\n",
      "total run time: 45.093109999999996\n",
      "CPU/GPU/RAM bottleneck time: 36.13007900000001\n",
      "Disk IO bottleneck time: 8.963030999999987\n",
      "\n",
      "Run complete\n",
      "overall time: 45.09337099999999\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "print('\\nProcessing image files to 512x512 color or grayscale arrays')\n",
    "# Create cats_1000_512_512_3 and numpy array for 1000 cat images in color\n",
    "cats_1000_512_512_3 = np.zeros((1000, 512, 512, 3))  \n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_color_and_resize(image_file_path, size = (512, 512))\n",
    "    cats_1000_512_512_3[ifile,:,:,:] = image\n",
    "       \n",
    "# Create dogs_1000_512_512_3 and numpy array for 1000 dog images in color   \n",
    "dogs_1000_512_512_3 = np.zeros((1000, 512, 512, 3))  \n",
    "for ifile in range(len(dog_file_names)):\n",
    "    image_file_path = os.path.join(dog_image_dir_name, dog_file_names[ifile])\n",
    "    image = parse_color_and_resize(image_file_path, size = (512, 512))\n",
    "    dogs_1000_512_512_3[ifile,:,:,:] = image\n",
    "\n",
    "# Create cats_1000_512_512_1 and numpy array for 1000 cat images in grayscale\n",
    "cats_1000_512_512_1 = np.zeros((1000, 512, 512, 1))  \n",
    "for ifile in range(len(cat_file_names)):\n",
    "    image_file_path = os.path.join(cat_image_dir_name, cat_file_names[ifile])\n",
    "    image = parse_grayscale_and_resize(image_file_path, size = (512, 512))\n",
    "    cats_1000_512_512_1[ifile,:,:,0] = image\n",
    "       \n",
    "# Create dogs_1000_512_512_1 and numpy array for 1000 dog images in grayscale   \n",
    "dogs_1000_512_512_1 = np.zeros((1000, 512, 512, 1))  \n",
    "for ifile in range(len(dog_file_names)):\n",
    "    image_file_path = os.path.join(dog_image_dir_name, dog_file_names[ifile])\n",
    "    image = parse_grayscale_and_resize(image_file_path, size = (512, 512))\n",
    "    dogs_1000_512_512_1[ifile,:,:,0] = image\n",
    "    \n",
    "# Save numpy array objects for analysis \n",
    "disk_time_m1=time.clock()\n",
    "np.save(os.path.join(outdir, 'cats_1000_512_512_3.npy'), cats_1000_512_512_3)\n",
    "np.save(os.path.join(outdir, 'dogs_1000_512_512_3.npy'), dogs_1000_512_512_3)\n",
    "np.save(os.path.join(outdir, 'cats_1000_512_512_1.npy'), cats_1000_512_512_1)\n",
    "np.save(os.path.join(outdir, 'dogs_1000_512_512_1.npy'), dogs_1000_512_512_1)\n",
    "disk_time= disk_time + time.clock() - disk_time_m1\n",
    "# Record end time for neral network training\n",
    "\n",
    "#Total processing time\n",
    "runtime_M1 = time.clock() - start_time_overall\n",
    "print(\"total run time:\", runtime_M1)\n",
    "print(\"CPU/GPU/RAM bottleneck time:\", runtime_M1 - disk_time)\n",
    "print(\"Disk IO bottleneck time:\", disk_time)\n",
    "print('\\nRun complete')    \n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Data Analysis & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Functions & variables  #restart here\n",
    "random_seed=9999\n",
    "\n",
    "#Reset Graphs for Tensorboard\n",
    "def reset_graph(seed= random_seed):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "#Save images to working directory\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(work_dir, \"images\", chp_id, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "    \n",
    "\n",
    "#Randomly Sort Batches\n",
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "        \n",
    "\n",
    "from matplotlib import pyplot as plt  # for display of images\n",
    "def show_grayscale_image(image):\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#Check distribtion of test , valid and train\n",
    "#def dist_plot(var1, var2, var3):\n",
    "  #  tmp_plt=sns.countplot(var1, palette=\"Blues\").set_title(var2)\n",
    " #   tmp_fig = tmp_plt.get_figure()\n",
    "  #  tmp_fig.savefig(var3 + \".png\", \n",
    "   #     bbox_inches = 'tight', dpi=None, facecolor='w', edgecolor='b', \n",
    "    #    orientation='portrait', papertype=None, format=None, \n",
    "     #   transparent=True, pad_inches=0.25, frameon=None)\n",
    "    #return(tmp_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cat data:  (1000, 64, 64, 1)\n",
      "Shape of dog data:  (1000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "# CatsDogs  dataset # \n",
    "# Documentation on npy binary format for saving numpy arrays for later use\n",
    "#     https://towardsdatascience.com/why-you-should-start-using-npy-file-more-often-df2a13cc0161\n",
    "# Under the working directory, data files are in directory cats_dogs_64_128 \n",
    "# Read in cats and dogs grayscale 64x64 files to create training data\n",
    "cats_1000_64_64_1 = np.load('./cats_dogs_arrays_1000/cats_1000_64_64_1.npy')\n",
    "dogs_1000_64_64_1 = np.load('./cats_dogs_arrays_1000/dogs_1000_64_64_1.npy')\n",
    "\n",
    "print(\"Shape of cat data: \",cats_1000_64_64_1.shape)\n",
    "print(\"Shape of dog data: \",dogs_1000_64_64_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1e04aaef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1e04c0cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine first cat and first dog grayscale images\n",
    "show_grayscale_image(cats_1000_64_64_1[0,:,:,0])\n",
    "show_grayscale_image(dogs_1000_64_64_1[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base Model: DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 300 and 100 nodes for layers 1 and 2 as used with MNIST from Geron\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "\n",
    "channels = 1  # When working with color images use channels = 3\n",
    "\n",
    "n_inputs = 64*64\n",
    "\n",
    "#CatsDogs# Has two output values # MNIST had ten digits n_outputs = 10  \n",
    "n_outputs = 2  # binary classification for Cats and Dogs, 1 output node 0/1\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dnn... Deep neural network model from Geron Chapter 10\n",
    "# Note that this model makes no use of the fact that we have\n",
    "# pixel data arranged in rows and columns\n",
    "# So a 64x64 matrix of raster values becomes a vector of 4096 input variables\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NN\n",
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall time: 45.690421\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")\n",
    "    \n",
    "\n",
    "# Loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "# Optimizer    \n",
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))    \n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work the data for cats and dogs numpy arrays \n",
    "# These numpy arrays were generated in previous data prep work\n",
    "# Stack the numpy arrays for the inputs\n",
    "X_cat_dog = np.concatenate((cats_1000_64_64_1, dogs_1000_64_64_1), axis = 0) \n",
    "X_cat_dog = X_cat_dog.reshape(-1,64*64) # note coversion to 4096 inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall time: 45.803095\n"
     ]
    }
   ],
   "source": [
    "# Scikit Learn for min-max scaling of the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(np.array([0., 255.]).reshape(-1,1)) \n",
    "X_cat_dog_min_max = scaler.transform(X_cat_dog)\n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels to be used 1000 cats = 0 1000 dogs = 1\n",
    "y_cat_dog = np.concatenate((np.zeros((1000), dtype = np.int32), \n",
    "                      np.ones((1000), dtype = np.int32)), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training data:  (1600, 4096)\n",
      "Shape of Test data:  (400, 4096)\n",
      "\n",
      "Shape of Training data:  (1600,)\n",
      "Shape of Test data:  (400,)\n"
     ]
    }
   ],
   "source": [
    "# Random splitting of the data in to training (80%) and test (20%)  \n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X_cat_dog_min_max, y_cat_dog, test_size=0.20, \n",
    "                     random_state = random_seed)\n",
    "\n",
    "print(\"Shape of Training data: \", X_train.shape)\n",
    "print(\"Shape of Test data: \", X_test.shape)\n",
    "\n",
    "print(\"\\nShape of Training data: \", y_train.shape)\n",
    "print(\"Shape of Test data: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.64 Test accuracy: 0.5075\n",
      "1 Train accuracy: 0.63 Test accuracy: 0.51\n",
      "2 Train accuracy: 0.64 Test accuracy: 0.52\n",
      "3 Train accuracy: 0.65 Test accuracy: 0.52\n",
      "4 Train accuracy: 0.64 Test accuracy: 0.515\n",
      "5 Train accuracy: 0.66 Test accuracy: 0.5225\n",
      "6 Train accuracy: 0.67 Test accuracy: 0.5325\n",
      "7 Train accuracy: 0.7 Test accuracy: 0.525\n",
      "8 Train accuracy: 0.68 Test accuracy: 0.52\n",
      "9 Train accuracy: 0.69 Test accuracy: 0.535\n",
      "10 Train accuracy: 0.69 Test accuracy: 0.5325\n",
      "11 Train accuracy: 0.71 Test accuracy: 0.5275\n",
      "12 Train accuracy: 0.73 Test accuracy: 0.535\n",
      "13 Train accuracy: 0.68 Test accuracy: 0.52\n",
      "14 Train accuracy: 0.7 Test accuracy: 0.5275\n",
      "15 Train accuracy: 0.74 Test accuracy: 0.535\n",
      "16 Train accuracy: 0.77 Test accuracy: 0.535\n",
      "17 Train accuracy: 0.79 Test accuracy: 0.535\n",
      "18 Train accuracy: 0.75 Test accuracy: 0.5275\n",
      "19 Train accuracy: 0.78 Test accuracy: 0.555\n",
      "20 Train accuracy: 0.79 Test accuracy: 0.5825\n",
      "21 Train accuracy: 0.82 Test accuracy: 0.5975\n",
      "22 Train accuracy: 0.82 Test accuracy: 0.5925\n",
      "23 Train accuracy: 0.81 Test accuracy: 0.5925\n",
      "24 Train accuracy: 0.68 Test accuracy: 0.5175\n",
      "25 Train accuracy: 0.64 Test accuracy: 0.4975\n",
      "26 Train accuracy: 0.82 Test accuracy: 0.54\n",
      "27 Train accuracy: 0.72 Test accuracy: 0.515\n",
      "28 Train accuracy: 0.82 Test accuracy: 0.6\n",
      "29 Train accuracy: 0.82 Test accuracy: 0.6\n",
      "30 Train accuracy: 0.83 Test accuracy: 0.595\n",
      "31 Train accuracy: 0.83 Test accuracy: 0.5975\n",
      "32 Train accuracy: 0.75 Test accuracy: 0.5225\n",
      "33 Train accuracy: 0.66 Test accuracy: 0.51\n",
      "34 Train accuracy: 0.68 Test accuracy: 0.5175\n",
      "35 Train accuracy: 0.7 Test accuracy: 0.5125\n",
      "36 Train accuracy: 0.68 Test accuracy: 0.5125\n",
      "37 Train accuracy: 0.68 Test accuracy: 0.515\n",
      "38 Train accuracy: 0.72 Test accuracy: 0.5425\n",
      "39 Train accuracy: 0.8 Test accuracy: 0.58\n",
      "40 Train accuracy: 0.82 Test accuracy: 0.5975\n",
      "41 Train accuracy: 0.8 Test accuracy: 0.58\n",
      "42 Train accuracy: 0.81 Test accuracy: 0.5825\n",
      "43 Train accuracy: 0.86 Test accuracy: 0.5975\n",
      "44 Train accuracy: 0.87 Test accuracy: 0.5925\n",
      "45 Train accuracy: 0.76 Test accuracy: 0.5575\n",
      "46 Train accuracy: 0.88 Test accuracy: 0.5975\n",
      "47 Train accuracy: 0.86 Test accuracy: 0.545\n",
      "48 Train accuracy: 0.78 Test accuracy: 0.5275\n",
      "49 Train accuracy: 0.74 Test accuracy: 0.5225\n",
      "INFO:tensorflow:Restoring parameters from ./my_catdog_model\n",
      "-------- Model 1 --------\n",
      "\n",
      "Predicted classes: [1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1]\n",
      "Actual classes: [0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0]\n",
      "Test Set Accuracy: 0.5225\n",
      "processing time: 2.7739290000000096\n",
      "overall time: 48.63126299999999\n"
     ]
    }
   ],
   "source": [
    "#Training base model by using DNN\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "# Record start time for neural network training\n",
    "start_time_base = time.clock()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(y_train.shape[0] // batch_size):\n",
    "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
    "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train_base = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test_base = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train_base, \"Test accuracy:\", acc_test_base)\n",
    "\n",
    "        save_path = saver.save(sess, \"./my_catdog_model\")\n",
    "# Predict using the test dataset\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_catdog_model\") # or better, use save_path\n",
    "    X_new_scaled = X_test[:50]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred_base = np.argmax(Z, axis=1)\n",
    "    accuracy_base = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "# Print Metrics\n",
    "print(\"-------- Model 1 --------\")\n",
    "print(\"\\nPredicted classes:\", y_pred_base)\n",
    "print(\"Actual classes:\", y_test[:25])\n",
    "print(\"Test Set Accuracy:\", accuracy_base)\n",
    "\n",
    "# Record end time for neural network training\n",
    "stop_time_base = time.clock()\n",
    "\n",
    "#Total processing time\n",
    "runtime_base = stop_time_base - start_time_base \n",
    "\n",
    "\n",
    "print(\"processing time:\", runtime_base)\n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Convolution Neural Nets (CNNs) : Model 1\n",
    "Model 1 : CNN (Convolutional Layer: 2, Pooling Layer: 1, Fully Connected Layer: 1, Activation Function: ReLU, Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall time: 48.641718\n"
     ]
    }
   ],
   "source": [
    "#CatsDocs image has 64x64 matrix of raster values becomes a vector of 4096 input variables\n",
    "tf.Session.close\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 1 #1 is used for gray scale color. \n",
    "n_inputs = height * width #64x64 - 4096 features\n",
    "\n",
    "#Parameters for the 1st convolutional layer. \n",
    "conv1_fmaps = 32 #number of filters in the convolution\n",
    "conv1_ksize = 3 #Karnel Size\n",
    "conv1_stride = 1 #Straides\n",
    "conv1_pad = \"SAME\" #Padding\n",
    "\n",
    "#Parameters for the 2nd convolutional layer. \n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "#Parameters  pooling layer \n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "#Fully Connected Layer  pooling layer \n",
    "n_fc1 = 64 # Dmensionality of the output space.\n",
    "n_outputs = 2 #2 values, Cat or Dog\n",
    "\n",
    "#Refresh previous graph\n",
    "reset_graph()\n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall time: 48.6776\n"
     ]
    }
   ],
   "source": [
    "### Construction Phase###\n",
    "\n",
    "# Construct convolutional layers\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall time: 48.709001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construct pooling layers\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps*16*16])\n",
    "\n",
    "# Construct fully connected layer\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "# Outputs Layer with applying softmax function\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall time: 48.838847\n"
     ]
    }
   ],
   "source": [
    "# Training with AdamOptimizaer\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "# Evaluation       \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "## Create saver to save trained parameters\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.5 Test accuracy: 0.48\n",
      "overall time: 49.692453\n"
     ]
    }
   ],
   "source": [
    "### Execution Phase###\n",
    "# Set number of epochs and batch size for training model.\n",
    "# Record start time for neural network training\n",
    "n_epochs = 1\n",
    "batch_size = 10\n",
    "\n",
    "# Record start time for neural network training\n",
    "start_time_base = time.clock()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(y_train.shape[0] // batch_size):\n",
    "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
    "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train_base = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test_base = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train_base, \"Test accuracy:\", acc_test_base)\n",
    "\n",
    "        save_path = saver.save(sess, \"./my_catdog_model\")\n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_catdog_model\n",
      "-------- Model 1 --------\n",
      "\n",
      "Predicted classes: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Actual classes: [0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0]\n",
      "Test Set Accuracy: 0.48\n",
      "processing time: 0.9030879999999968\n",
      "overall time: 49.75132099999999\n"
     ]
    }
   ],
   "source": [
    "# Predict using the test dataset\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_catdog_model\") # or better, use save_path\n",
    "    X_new_scaled = X_test[:50]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred_base = np.argmax(Z, axis=1)\n",
    "    accuracy_base = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "# Print Metrics\n",
    "print(\"-------- Model 1 --------\")\n",
    "print(\"\\nPredicted classes:\", y_pred_base)\n",
    "print(\"Actual classes:\", y_test[:25])\n",
    "print(\"Test Set Accuracy:\", accuracy_base)\n",
    "\n",
    "# Record end time for neural network training\n",
    "stop_time_base = time.clock()\n",
    "\n",
    "#Total processing time\n",
    "runtime_base = stop_time_base - start_time_base \n",
    "\n",
    "print(\"processing time:\", runtime_base)\n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Convolution Neural Nets (CNNs) : Model 2\n",
    "CNN (Convolutional Layer: 3, Pooling Layer: 1, Fully Connected Layer: 1, Activation Function: ReLU, Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.Session.close\n",
    "#CatsDocs image has 64x64 matrix of raster values becomes a vector of 4096 input variables\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 1 #1 is used for gray scale color. \n",
    "n_inputs = height * width #64x64 - 4096 features\n",
    "\n",
    "#Parameters for the 1st convolutional layer. \n",
    "conv1_fmaps = 32 #number of filters in the convolution\n",
    "conv1_ksize = 3 #Karnel Size\n",
    "conv1_stride = 1 #Straides\n",
    "conv1_pad = \"SAME\" #Padding\n",
    "\n",
    "#Parameters for the 2nd convolutional layer. \n",
    "conv2_fmaps = 64\n",
    "conv2_ksize = 3\n",
    "conv2_stride = 2\n",
    "conv2_pad = \"SAME\"\n",
    "\n",
    "#Parameters  pooling layer \n",
    "pool3_fmaps = conv2_fmaps\n",
    "\n",
    "#Fully Connected Layer  pooling layer \n",
    "n_fc1 = 64 # Dmensionality of the output space.\n",
    "n_outputs = 2 #2 values, Cat or Dog\n",
    "\n",
    "#Refresh previous graph\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construction Phase###\n",
    "\n",
    "# Construct convolutional layers\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, n_inputs], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conva = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=conv1_pad,\n",
    "                         activation=tf.nn.relu, name=\"conva\")\n",
    "convb = tf.layers.conv2d(conva, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=conv2_pad,\n",
    "                         activation=tf.nn.relu, name=\"convb\")\n",
    "\n",
    "# Construct pooling layers\n",
    "with tf.name_scope(\"pool3\"):\n",
    "    pool3 = tf.nn.max_pool(convb, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool3_flat = tf.reshape(pool3, shape=[-1, pool3_fmaps*16*16])\n",
    "\n",
    "# Construct fully connected layer\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(pool3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "# Outputs Layer with applying softmax function\n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc1, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "# Training with AdamOptimizaer\n",
    "with tf.name_scope(\"train\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "# Evaluation       \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "## Create saver to save trained parameters\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "1 Train accuracy: 0.59 Test accuracy: 0.48\n",
      "2 Train accuracy: 0.64 Test accuracy: 0.525\n",
      "3 Train accuracy: 0.68 Test accuracy: 0.6025\n",
      "4 Train accuracy: 0.7 Test accuracy: 0.6075\n",
      "5 Train accuracy: 0.77 Test accuracy: 0.6175\n",
      "6 Train accuracy: 0.79 Test accuracy: 0.62\n",
      "7 Train accuracy: 0.79 Test accuracy: 0.6125\n",
      "8 Train accuracy: 0.82 Test accuracy: 0.6125\n",
      "9 Train accuracy: 0.85 Test accuracy: 0.635\n",
      "10 Train accuracy: 0.86 Test accuracy: 0.6475\n",
      "11 Train accuracy: 0.93 Test accuracy: 0.64\n",
      "12 Train accuracy: 0.91 Test accuracy: 0.6675\n",
      "13 Train accuracy: 0.96 Test accuracy: 0.6575\n",
      "14 Train accuracy: 0.97 Test accuracy: 0.6325\n",
      "15 Train accuracy: 0.9 Test accuracy: 0.6275\n",
      "16 Train accuracy: 0.98 Test accuracy: 0.66\n",
      "17 Train accuracy: 0.96 Test accuracy: 0.6525\n",
      "18 Train accuracy: 0.99 Test accuracy: 0.65\n",
      "19 Train accuracy: 1.0 Test accuracy: 0.6525\n",
      "20 Train accuracy: 1.0 Test accuracy: 0.6175\n",
      "21 Train accuracy: 1.0 Test accuracy: 0.63\n",
      "22 Train accuracy: 1.0 Test accuracy: 0.6225\n",
      "23 Train accuracy: 1.0 Test accuracy: 0.645\n",
      "24 Train accuracy: 1.0 Test accuracy: 0.645\n",
      "25 Train accuracy: 1.0 Test accuracy: 0.62\n",
      "26 Train accuracy: 1.0 Test accuracy: 0.635\n",
      "27 Train accuracy: 1.0 Test accuracy: 0.63\n",
      "28 Train accuracy: 1.0 Test accuracy: 0.63\n",
      "29 Train accuracy: 1.0 Test accuracy: 0.64\n",
      "30 Train accuracy: 1.0 Test accuracy: 0.6375\n",
      "31 Train accuracy: 1.0 Test accuracy: 0.635\n",
      "32 Train accuracy: 1.0 Test accuracy: 0.6325\n",
      "33 Train accuracy: 1.0 Test accuracy: 0.6325\n",
      "34 Train accuracy: 1.0 Test accuracy: 0.63\n",
      "35 Train accuracy: 1.0 Test accuracy: 0.63\n",
      "36 Train accuracy: 1.0 Test accuracy: 0.6275\n",
      "37 Train accuracy: 1.0 Test accuracy: 0.62\n",
      "38 Train accuracy: 1.0 Test accuracy: 0.615\n",
      "39 Train accuracy: 1.0 Test accuracy: 0.625\n",
      "40 Train accuracy: 1.0 Test accuracy: 0.625\n",
      "41 Train accuracy: 1.0 Test accuracy: 0.6225\n",
      "42 Train accuracy: 1.0 Test accuracy: 0.6275\n",
      "43 Train accuracy: 1.0 Test accuracy: 0.615\n",
      "44 Train accuracy: 1.0 Test accuracy: 0.6075\n",
      "45 Train accuracy: 1.0 Test accuracy: 0.6075\n",
      "46 Train accuracy: 1.0 Test accuracy: 0.605\n",
      "47 Train accuracy: 1.0 Test accuracy: 0.6025\n",
      "48 Train accuracy: 1.0 Test accuracy: 0.5975\n",
      "49 Train accuracy: 1.0 Test accuracy: 0.5975\n",
      "INFO:tensorflow:Restoring parameters from ./my_catdog_model\n",
      "-------- Model 1 --------\n",
      "\n",
      "Predicted classes: [0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 1 1 1 1 1 1 0 1 1 1]\n",
      "Actual classes: [0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 1 1 1 0 0]\n",
      "Test Set Accuracy: 0.5975\n",
      "processing time: 10.128751999999992\n",
      "overall time: 60.15267\n"
     ]
    }
   ],
   "source": [
    "### Execution Phase###\n",
    "# Set number of epochs and batch size for training model.\n",
    "# Record start time for neural network training\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "# Record start time for neural network training\n",
    "start_time_base = time.clock()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(y_train.shape[0] // batch_size):\n",
    "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
    "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train_base = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test_base = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "        print(epoch, \"Train accuracy:\", acc_train_base, \"Test accuracy:\", acc_test_base)\n",
    "\n",
    "        save_path = saver.save(sess, \"./my_catdog_model\")\n",
    "# Predict using the test dataset\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_catdog_model\") # or better, use save_path\n",
    "    X_new_scaled = X_test[:50]\n",
    "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    y_pred_base = np.argmax(Z, axis=1)\n",
    "    accuracy_base = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "# Print Metrics\n",
    "print(\"-------- Model 1 --------\")\n",
    "print(\"\\nPredicted classes:\", y_pred_base)\n",
    "print(\"Actual classes:\", y_test[:25])\n",
    "print(\"Test Set Accuracy:\", accuracy_base)\n",
    "\n",
    "# Record end time for neural network training\n",
    "stop_time_base = time.clock()\n",
    "\n",
    "#Total processing time\n",
    "runtime_base = stop_time_base - start_time_base \n",
    "\n",
    "\n",
    "print(\"processing time:\", runtime_base)\n",
    "runtime_overall= time.clock() - start_time_overall\n",
    "print(\"overall time:\", runtime_overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Convolution Neural Nets (CNNs) : Model 3\n",
    "CNN with Dropout (....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Convolution Neural Nets (CNNs) : Model 4\n",
    "CNN with Dropout (.....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Try with different image resolutions as well "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'runtime_M2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-328d5eaeb8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0;34m'Relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Relu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Yes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Yes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m               \u001b[0;34m[\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_M1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_M2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_M3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_M4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0macc_train_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train_M1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train_M2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train_M3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_train_M4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m               [accuracy_base, accuracy_M1, accuracy_M2, accuracy_M3, accuracy_M4]] ).T\n",
      "\u001b[0;31mNameError\u001b[0m: name 'runtime_M2' is not defined"
     ]
    }
   ],
   "source": [
    "# Import panda to create summary table\n",
    "import pandas as pd\n",
    "\n",
    "summary_DF =\\\n",
    "pd.DataFrame([[\"Base\", \"M1\", \"M2\", \"M3\", \"M4\"],\n",
    "              [\"DNN\", \"CNN\", \"CNN\", \"CNN\", \"CNN\"],\n",
    "              ['',2,4,2,4],\n",
    "              ['',1,2,1,2],\n",
    "              ['',1,1,1,1],\n",
    "              ['Relu','Relu','Relu','Relu','Relu'],\n",
    "              ['No','No','No','Yes','Yes'],\n",
    "              [round(runtime_base,1), round(runtime_M1,1), round(runtime_M2,1), round(runtime_M3,), round(runtime_M4,1)],\n",
    "              [acc_train_base, acc_train_M1, acc_train_M2, acc_train_M3, acc_train_M4],\n",
    "              [accuracy_base, accuracy_M1, accuracy_M2, accuracy_M3, accuracy_M4]] ).T\n",
    "\n",
    "# Column Name and Index\n",
    "summary_DF.columns = [\"Model\",\"Neural\\nNetwork\\nType\", \"Convolutional\\nLayers\", \"Pooling\\nLayers\", \"Fully\\nConnected\\nLayers\",\n",
    "                      \"Activate\\nFunction\",\"Dropout\",\"Run_Time\",\"Training_Set\\nAccuracy\",\"Test_Set\\nAccuracy\"]\n",
    "summary_DF.index   = [1,2,3,4,5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------------------- Summary Table -------------------------------')\n",
    "summary_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Management Problem : \n",
    "Assume that we are providing advice to a website provider who is looking for tools to automatically label images provided by end users. As we look across the factors in the study, making recommendations to management about image classification, we are most concerned about achieving the highest possible accuracy in image classification. That is, we should be willing to sacrifice training time for model accuracy. What type of machine learning model works best? If it is a convolutional neural network, what type of network should we use? Part of this recommendation may concern information about the initial images themselves (input data for the classification task). What types of images work best ?\n",
    "\n",
    "\n",
    "#### REPORT/FINDINGS: \n",
    "(1) A summary and problem definition for management; \n",
    "\n",
    "(2) Discussion of the research design, measurement and statistical methods, traditional and machine learning methods employed \n",
    "\n",
    "(3) Overview of programming work; \n",
    "\n",
    "(4) Review of results with recommendations for management.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
